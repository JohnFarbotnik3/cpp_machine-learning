

* create optimized variants of the simplified network modules in the "networks"
folder by copying file, appending "_o1", "_o2", etc. and then optimizing whatever looks like
it will produce the biggest speedup.
^ in particular, reducing size of neuron structures by extracting values/value-histories from neurons,
as well as per-iteration loss, in order to get better data-locality.


* how to train weights and biases:
https://dustinstansbury.github.io/theclevermachine/derivation-backpropagation


> create visualizations showing the actual neural network itself.
- have rendering functions drawing layers as a W x H grid of neurons.
- also draw connections and activation values.
* this can help locate and troubleshoot intialization bugs/typos.
* this would also be very pretty.
- layers and graphs will require slightly (or significantly) different drawing logic.
* allow directly modifying model parameters by clicking on a neuron or connection.
^ when neuron or connection is clicked, it is added to a list.
^ each list item will have a group of sliders/text-inputs for modifying value.


* it might make sense to add W x H dimensions to the sub-networks (layer/graph) themselves,
as it gives clues about what the layer is for, as well as hinting at preferred memory layout.



> frontend:
! start by implementing and testing as a CLI program, then try to connect it to a browser after.
* NOTE: model input data will be put in a folder near the application binary
^ TODO: add config file with:
	- input-directory
	- model-directory
	- output-directory (for when user saves autoencoder image outputs)
- controls:
	- slider: learning rate (exponential scaling)
	- slider: batch size
	- buttons: reset / start / stop
- logistics:
	- graph: error
	- div: time taken per iteration / mini-batch / full-batch
	- div: # files in dataset / total size (MiB)
	- div: # neurons / # connections
	- image: input / output
	- canvas: model render (neurons and connections)
- model interactions (at a later-stage in project):
	- manipulate embedding values then propage decoder
	- set custom input image then run autoencoder (without applying training)
...



> alternative to graph:
- use multiple images instead of huge amorphous graph.
- each layer Z has connections pointing to layers { INPUT, OUTPUT, Z-1, Z, Z+1 }.


> graph multithreading - partitions:
- if the graph can be partitioned such that the vast majority of the connections
in each partition point to other neurons in the same partition, with only a few pointing externally,
the that would allow decent multithreading.


> optimize autoencoder.
* figure out why backprop (specifically the weights part) isnt scaling well with number of threads.
	n_threads=1: foreward=60ms, backprop=70ms
	n_threads=2: foreward=31ms, backprop=57ms
* running "perf" and doing a couple other experiments didnt reveal anything in particular (ex. "false sharing"),
but I highly suspect that memory bandwidth may be a problem. I may be time to implement
image tiling iterators meanwhile also implementing images + layer-generation with variable number of channels.
(this will be an overhaul)
* NOTE: running "perf record -- COMMAND [OPTIONS...]" then "perf report" can show
useful information about program hotspots.
- test image iterators (by printing indices and coordinates).
- create variable_image.
- use variable_image in autoencoder (mostly replacing sample_image).
*** currently connections make up majority of memory usage and memory pressure,
	however using a value+signal history equal to batch size would allow loading each
	neuron's connection list once, then processing multiple images,
	then backpropagating for each of the images.
	^ this would allow removing the batch-error accumulators, significantly reducing memory usage;
	and backprop would directly apply adjustments instead.
	^ back-targets could be removed completely and write-style
	backprop could be used (but then it would become single threaded).
	^ neurons could store history of values and signals inside itself
	so that images dont need to be interleaved.
	^ outside source can keep track of current history number,
	sending it to prop and backprop functions so they know
	which history entry to populate, or how many to backprop for.
	(this is also useful for cases where minibatches occasionally have odd sizes.)
	^ history could be stored in its own vector image, but with H times the number of channels.
	the index to access would then be neuron_index * H.
	^ fixed architecture layers would reduce memory consumption considerably as well,
	but would involve using iterators extensively, increasing cpu load.
	(each layer would have values keeping track of which iterator and iterator-parameters to use.)
	^ multi-threaded backprop may still benefit from target indices since inverse mapping
	could be complicated, particularly around edges of image.
- use memcpy instead of using "=" to set vector data,
as it may improve performance by reducing allocations.
^ WARNING: memcpy is risky since its really easy to make typos (such as forgetting to multiply by sizeof).
	write a vec_memcpy function which for copying ranges in vectors, which calls memcpy and DOESNT have typos.
- some parts of backprop are not yet multithreaded (ex: error normalization).
- there is room to introduce SIMD.


> Gaussian splatting based image compression.
* Gaussian splatting might be able to recreate images with FAR fewer parameters than an autoencoder.
^ it may make sense to break images into sections whose output contents dont spill over (output clipping).
^ drawing Gaussians may be expensive, try to find way to make it inexpensive.
^ each output tile should be able to see local part of input at full resultion,
	and whole image at some reduced resolution (for added context).
...



> misc
- add a dense connection push-layer function (all inputs connected to all outputs).
- autoencoder: experiment with lower bias values and lower ReLU leakage.
- add stochastic-back-anneal function which simply anneals with temperature
proportional to error of that particular neuron, then backprops that error.
^ this may be useful if the error function doesnt have direction information.
- graph backprop can have a queue of neurons to update during
next backprop iteration, with their respective local losses.
- fix console stuttering by buffering a few lines and then committing them at times
that would result in good looking / well aligned prints.
* idea: graph model can have both fixed architecture links and flexible links.
both would be processed during foreward & backward propagation; however this would
make implementation more complex (but faster and more memory efficient).
^^ note: switching back to scanlines would make coordinates and indices
far easier to work with.
- pick better commandline parameter names.
** storing value-history and signal-history might not be worth it,
as it limits the maximum batch size to 5-10. a good idea
for improving backprop performance might be to keep adjustments
seperate from the other values rather than interleaving them like I did before
with the layer_neuron struct.
- write more convenient thread spawning functions (variadic) so that I dont have to repeat the
same threads-over-intervals code over and over again.



> create X_O1 variant of autoencoder with fixed layer type.
	* autoencoder doesnt need flexible targeting scheme.
	* instead of having "autoencoder.cpp" in "./projects", have "./projects/autoencoder_o1" and "./.../main.cpp"
	* put current autoencoder project in "./projects/autoencoder",
		including the relevant image typedefs and loading functions;
		but dont actually move the variable_image and variable_image_tiled structs
		out of "image.cpp", as they may still see general use.
	- revert images back to being scanline-based (create non-tiled variant of image).
	- iterate over x,y coordinates.
	- store weights and weight-errors in layer itself.
	- store layer type, dimensions, etc. for proper iteration when reading from input
	during propagation and when reading to input during backprop.
	- propagate and backprop function variants will be needed for each layer type.
	- implement custom "foreward_target_list" type which stores offsets, weights, and weight-errors.
	^ when applying batch error, it is sufficient to just iterate through whole target list.
...


> multithreaded fixed-autoencoder.
* a semi-general solution to multithreading an autoencoder would be to split each image and each layer into subimages.
^ these subimages would benefit from having padding pixels (for both input and output)
which contain data from adjacent subimages, or are initialized to 0 if out of bounds
^ padding would allow getting rid of some bounds checks, as well as pre-computing tables
of offsets for input area (if thats even needed - it probably wont be with the algorithm simplifications).
^ this would get some of the benefits of tiled images too, since the scanlines would be shorter.
^ write-style operations would be less of a concern.
^ create a padded_value_image type for this. having a good get_offset(x,y,c) function would help a lot.
- there should be some minimum subimage size (ex. 64*64 or 128*128),
because otherwise thread-spawning and padding-exchange would add too much overhead.
* it may help to use the fw/bp target paradigm for better data locality during backprop,
but the target_index doesnt need to be computed; batch_apply_error can handle the inverse mapping,
and some things will be made simpler by having a *fixed* number of targets for each neuron (some of which will be unused).
^ neuron_index may not be needed either?
* we may want to store extra info in the layers for keeping track of properties of subimages.



> debug autoencoder.
- add config file parsing (newline delimited KEY=VALUE pairs).
* work on model ergonomics first:
	- config files: commandline parameters in text file.
	- model save/load: launch-config, current-settings, model-parameters, training-logs.
	- interactive console: log training stuff, but also allow typing commands,
		such as changing settings, play/pause, and save/load.
	- custom loggers: each one with a different file it accumulates into.
		every message should have format: { timestamp, log_level, text }.
		(will involve lots of snprintf, or writing variadic functions of my own.
		if writing my own, try javascript style names like "console.log(...)".)
** add simple annealing, and an interval over which to compare training
	of model variants with different annealing seeds & strengths (ex. LR*0, LR*0.5, LR*1.0, LR*2.0).
** try smaller bias distribution (reduced stdev),
	and add commandline arguments for model-parameter distributions.
** clamp output image values when generating image files / previews.
x long run with 30 images crashed at z=~1000/2000, see logs.
^ remove assertion in backprop normalization that insum & outsum > 0,
and replace with an if-condition + a warning printed to console.
** try centering range of image values on 0.0 (currently [0.0, 1.0] which is centered on 0.5).
** generate sample images and output to specified temp directory, then use those for training instead
of using caching.
...


> subimage autoencoder
! only the inner part of output image participates in foreward-prop,
but the whole image - including padding - participates in back-prop.
* consider using function-pointers or template function-objects
for allowing re-use of different layer iteration algorithms;
then benchmark to examine performance.
* test complicated gather-style backprop performance vs
simple scatter-style backprop to quantify difference.
it would be strongly preferable to use simple backprop
and get rid of bp_targets altogether if the performance penalty is not too severe.


> add to journal:
- switching from ReLU with leakage to piecewise sigmoid to fix bias degeneration
	(biases tending towards larger values as backprop works it way to input layer).
...




