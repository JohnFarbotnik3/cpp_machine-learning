

* create optimized variants of the simplified network modules in the "networks"
folder by copying file, appending "_o1", "_o2", etc. and then optimizing whatever looks like
it will produce the biggest speedup.
^ in particular, reducing size of neuron structures by extracting values/value-histories from neurons,
as well as per-iteration loss, in order to get better data-locality.


* how to train weights and biases:
https://dustinstansbury.github.io/theclevermachine/derivation-backpropagation


> create visualizations showing the actual neural network itself.
- have rendering functions drawing layers as a W x H grid of neurons.
- also draw connections and activation values.
* this can help locate and troubleshoot intialization bugs/typos.
* this would also be very pretty.
- layers and graphs will require slightly (or significantly) different drawing logic.
* allow directly modifying model parameters by clicking on a neuron or connection.
^ when neuron or connection is clicked, it is added to a list.
^ each list item will have a group of sliders/text-inputs for modifying value.


* it might make sense to add W x H dimensions to the sub-networks (layer/graph) themselves,
as it gives clues about what the layer is for, as well as hinting at preferred memory layout.



> frontend:
! start by implementing and testing as a CLI program, then try to connect it to a browser after.
* NOTE: model input data will be put in a folder near the application binary
^ TODO: add config file with:
	- input-directory
	- model-directory
	- output-directory (for when user saves autoencoder image outputs)
- controls:
	- slider: learning rate (exponential scaling)
	- slider: batch size
	- buttons: reset / start / stop
- logistics:
	- graph: error
	- div: time taken per iteration / mini-batch / full-batch
	- div: # files in dataset / total size (MiB)
	- div: # neurons / # connections
	- image: input / output
	- canvas: model render (neurons and connections)
- model interactions (at a later-stage in project):
	- manipulate embedding values then propage decoder
	- set custom input image then run autoencoder (without applying training)
...


> todo - debug autoencoder.
- add config file parsing (newline delimited KEY=VALUE pairs).
- implement adaptive learning rate (based on avg_error).


